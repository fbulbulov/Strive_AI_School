{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Categorical encoders\n",
    "### <center> With [Scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features ) and [Category Encoders](https://contrib.scikit-learn.org/category_encoders/)\n",
    "    \n",
    "**This is a notebook from [Feature Engineering](https://www.kaggle.com/learn/feature-engineering) course. You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/categorical-encodings).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\anaconda\\lib\\site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\anaconda\\lib\\site-packages (from category_encoders) (1.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\anaconda\\lib\\site-packages (from category_encoders) (0.12.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\anaconda\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\anaconda\\lib\\site-packages (from category_encoders) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\anaconda\\lib\\site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\anaconda\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.1.3\n",
      "Sklearn  0.24.2\n",
      "lightgbm 3.2.1\n",
      "Cat Enc. 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn as skl\n",
    "from sklearn import impute\n",
    "from sklearn import pipeline\n",
    "from sklearn import compose\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram') # Useful for display the pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__)\n",
    "print(\"lightgbm\", lgb.__version__)\n",
    "print(\"Cat Enc.\", ce.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls ../../Datasets/Tabular/kickstarter-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Datasets/Tabular/kickstarter-projects/ks-projects-201801.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-dfe9c06f6384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../../Datasets/Tabular/kickstarter-projects/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df   = pd.read_csv(path+'ks-projects-201801.csv',\n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[1;31m#index_col=\"ID\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    parse_dates=['deadline', 'launched'])\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Datasets/Tabular/kickstarter-projects/ks-projects-201801.csv'"
     ]
    }
   ],
   "source": [
    "path = \"../../Datasets/Tabular/kickstarter-projects/\"\n",
    "df   = pd.read_csv(path+'ks-projects-201801.csv',\n",
    "                   #index_col=\"ID\",\n",
    "                   parse_dates=['deadline', 'launched'])\n",
    "\n",
    "# Drop live projects\n",
    "df = df.query('state != \"live\"')\n",
    "\n",
    "# Timestamp features\n",
    "df = df.assign(hour = df.launched.dt.hour,\n",
    "               day  = df.launched.dt.day,\n",
    "               month= df.launched.dt.month,\n",
    "               year = df.launched.dt.year)\n",
    "\n",
    "# Add target column, \"successful\" == 1, others are 0\n",
    "df[\"target\"] = (df['state'] == 'successful').astype(int)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['category', 'currency', 'country']\n",
    "num_vars = ['goal', 'hour', 'day', 'month', 'year']\n",
    "\n",
    "x = df[cat_vars + num_vars]\n",
    "y = df[\"target\"] # \"successful\" == 1, others are 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009478,
     "end_time": "2020-10-01T00:24:45.412525",
     "exception": false,
     "start_time": "2020-10-01T00:24:45.403047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoders = {\n",
    "    \"OneHot\":      ce.OneHotEncoder(cols = cat_vars),\n",
    "    \"Ordinal\":     ce.OrdinalEncoder(cols = cat_vars),\n",
    "    \"Binary\":      ce.BinaryEncoder(cols = cat_vars),\n",
    "    \"Count\":       ce.CountEncoder(cols = cat_vars, min_group_size=False),\n",
    "    \"Frequency\":   ce.CountEncoder(cols = cat_vars, min_group_size=False, normalize=True),\n",
    "    \"Target\":      ce.TargetEncoder(cols = cat_vars),\n",
    "    \"Target_LOO\":  ce.LeaveOneOutEncoder(cols = cat_vars),\n",
    "    \"Target_CatB\": ce.TargetEncoder(cols = cat_vars),\n",
    "}\n",
    "\n",
    "# OTHERS LESS COMMON CAT ENCODERS\n",
    "#\n",
    "# ce.BackwardDifferenceEncoder()\n",
    "# ce.BaseNEncoder()\n",
    "# ce.GLMMEncoder()\n",
    "# ce.HashingEncoder()\n",
    "# ce.HelmertEncoder()\n",
    "# ce.JamesSteinEncoder()\n",
    "# ce.MEstimateEncoder()\n",
    "# ce.SumEncoder()\n",
    "# ce.PolynomialEncoder()\n",
    "# ce.WOEEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def create_tree_prepro(cat_encoder):\n",
    "\n",
    "    num_prepro = pipeline.Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value=-9999)),\n",
    "    ])\n",
    "\n",
    "    cat_prepro = pipeline.Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ordinal', cat_encoder)\n",
    "    ])\n",
    "\n",
    "    tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "        ('num', num_prepro, num_vars),\n",
    "        ('cat', cat_prepro, cat_vars),\n",
    "    ], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "    return tree_prepro\n",
    "\n",
    "p= create_tree_prepro(cat_encoders[\"OneHot\"])\n",
    "p\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"db9548a3-3f48-4efa-973b-d4dbe07c4440\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"db9548a3-3f48-4efa-973b-d4dbe07c4440\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric='auc', num_leaves=64, objective='binary', seed=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='auc', num_leaves=64, objective='binary', seed=7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_lgb_model():\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "         num_leaves   = 64,\n",
    "         objective    = \"binary\",\n",
    "         metric       = \"auc\",\n",
    "         seed         = 7\n",
    "    #   n_estimators  = 7000\n",
    "    #   max_bin       = 128,\n",
    "    #   num_leaves    = 8,\n",
    "    #   reg_alpha     = 1.2,\n",
    "    #   reg_lambda    = 1.2,\n",
    "    #   min_data_in_leaf = 50,\n",
    "    #   bagging_fraction = 0.5,\n",
    "    #   learning_rate    = 0.001\n",
    "    #   n_jobs           = -1\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "create_lgb_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN 10 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-01T00:24:45.448938Z",
     "iopub.status.busy": "2020-10-01T00:24:45.448255Z",
     "iopub.status.idle": "2020-10-01T00:24:49.202582Z",
     "shell.execute_reply": "2020-10-01T00:24:49.203135Z"
    },
    "papermill": {
     "duration": 3.781918,
     "end_time": "2020-10-01T00:24:49.203326",
     "exception": false,
     "start_time": "2020-10-01T00:24:45.421408",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.748453\n",
      "OneHot AUC score: 64.1334\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.747264\n",
      "Ordinal AUC score: 63.904\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.744696\n",
      "Binary AUC score: 63.6053\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.744284\n",
      "Count AUC score: 63.91\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.744284\n",
      "Frequency AUC score: 63.91\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.744704\n",
      "Target AUC score: 64.0168\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[67]\tvalid_0's auc: 0.507791\n",
      "Target_LOO AUC score: 49.8669\n",
      "\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's auc: 0.744704\n",
      "Target_CatB AUC score: 64.0168\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for train_idxs, valid_idxs in skf.split(x, y):\n",
    "        \n",
    "    x_train, y_train = x.iloc[train_idxs], y.iloc[train_idxs]\n",
    "    x_valid, y_valid = x.iloc[valid_idxs], y.iloc[valid_idxs]\n",
    "\n",
    "    for cat_encoder_name, cat_encoder in cat_encoders.items():\n",
    "        \n",
    "        print()\n",
    "\n",
    "        # 1) PREPRO THE DATA\n",
    "        #prepro = create_tree_prepro(cat_encoder)\n",
    "        x_train_prepro = cat_encoder.fit_transform(x_train, y_train) # y_train ONLY USED IN TARGET ENCS\n",
    "        x_valid_prepro = cat_encoder.transform(x_valid)\n",
    "        \n",
    "        \n",
    "        # 2) TRAIN\n",
    "        model  = create_lgb_model()\n",
    "        model.fit(\n",
    "            X                     = x_train_prepro,\n",
    "            y                     = y_train,\n",
    "            eval_set              = [(x_valid_prepro, y_valid)],\n",
    "            eval_metric           = 'auc',\n",
    "            early_stopping_rounds = 2000,\n",
    "            verbose               = -1\n",
    "            #categorical_feature   = cat_vars,\n",
    "        )\n",
    "        \n",
    "        #from sklearn.ensemble import RandomForestClassifier\n",
    "        #model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        #model.fit(x_train_prepro, y_train)\n",
    "        \n",
    "        # 3) VALIDATE\n",
    "        valid_pred = model.predict(x_valid_prepro)\n",
    "        auc = metrics.roc_auc_score(y_valid, valid_pred) * 100\n",
    "        print(cat_encoder_name + \" AUC score: \" + str(round(auc, 4)))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:24:49.230021Z",
     "iopub.status.busy": "2020-10-01T00:24:49.228640Z",
     "iopub.status.idle": "2020-10-01T00:24:52.996995Z",
     "shell.execute_reply": "2020-10-01T00:24:52.997613Z"
    },
    "papermill": {
     "duration": 3.785292,
     "end_time": "2020-10-01T00:24:52.997795",
     "exception": false,
     "start_time": "2020-10-01T00:24:49.212503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "    valid_fraction = 0.1\n",
    "    valid_size = int(len(dataframe) * valid_fraction)\n",
    "\n",
    "    train = dataframe[:-valid_size * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_size * 2:-valid_size]\n",
    "    test = dataframe[-valid_size:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid):\n",
    "    feature_cols = train.columns.drop('outcome')\n",
    "\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['outcome'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['outcome'])\n",
    "\n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    bst = lgb.train(param, dtrain, num_boost_round=1000, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['outcome'], valid_pred)\n",
    "    print(f\"Validation AUC score: {valid_score:.4f}\")\n",
    "    \n",
    "    \n",
    "# Train a model (on the baseline data)\n",
    "train, valid, test = get_data_splits(data)\n",
    "train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012291,
     "end_time": "2020-10-01T00:24:53.022550",
     "exception": false,
     "start_time": "2020-10-01T00:24:53.010259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Count Encoding (aka Frequency Encoding)\n",
    "\n",
    "Count encoding replaces each categorical value with the number of times it appears in the dataset. For example, if the value \"GB\" occured 10 times in the country feature, then each \"GB\" would be replaced with the number 10.\n",
    "\n",
    "We'll use the [`categorical-encodings` package](https://github.com/scikit-learn-contrib/categorical-encoding) to get this encoding. The encoder itself is available as `CountEncoder`. This encoder and the others in `categorical-encodings` work like scikit-learn transformers with `.fit` and `.transform` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:24:53.055365Z",
     "iopub.status.busy": "2020-10-01T00:24:53.054447Z",
     "iopub.status.idle": "2020-10-01T00:24:58.446850Z",
     "shell.execute_reply": "2020-10-01T00:24:58.447431Z"
    },
    "papermill": {
     "duration": 5.412997,
     "end_time": "2020-10-01T00:24:58.447626",
     "exception": false,
     "start_time": "2020-10-01T00:24:53.034629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC score: 0.7486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat_features = ['category', 'currency', 'country']\n",
    "\n",
    "# Create the encoder\n",
    "count_enc = ce.CountEncoder()\n",
    "\n",
    "# Transform the features, rename the columns with the _count suffix, and join to dataframe\n",
    "count_encoded = count_enc.fit_transform(ks[cat_features])\n",
    "data = data.join(count_encoded.add_suffix(\"_count\"))\n",
    "\n",
    "# Train a model \n",
    "train, valid, test = get_data_splits(data)\n",
    "train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012139,
     "end_time": "2020-10-01T00:24:58.472479",
     "exception": false,
     "start_time": "2020-10-01T00:24:58.460340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adding the count encoding features increase the validation score from 0.7467 to 0.7486, only a slight improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012054,
     "end_time": "2020-10-01T00:24:58.497173",
     "exception": false,
     "start_time": "2020-10-01T00:24:58.485119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Target Encoding (aka Mean Encoding)\n",
    "\n",
    "Target encoding replaces a categorical value with the average value of the target for that value of the feature. For example, given the country value \"CA\", you'd calculate the average outcome for all the rows with `country == 'CA'`, around 0.28. This is often blended with the target probability over the entire dataset to reduce the variance of values with few occurences.\n",
    "\n",
    "This technique uses the targets to create new features. So including the validation or test data in the target encodings would be a form of target leakage. Instead, you should learn the target encodings from the training dataset only and apply it to the other datasets.\n",
    "\n",
    "The `category_encoders` package provides `TargetEncoder` for target encoding. The implementation is similar to `CountEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:24:58.535078Z",
     "iopub.status.busy": "2020-10-01T00:24:58.534238Z",
     "iopub.status.idle": "2020-10-01T00:25:02.959128Z",
     "shell.execute_reply": "2020-10-01T00:25:02.960276Z"
    },
    "papermill": {
     "duration": 4.449064,
     "end_time": "2020-10-01T00:25:02.960460",
     "exception": false,
     "start_time": "2020-10-01T00:24:58.511396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC score: 0.7491\n"
     ]
    }
   ],
   "source": [
    "# Create the encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "target_enc.fit(train[cat_features], train['outcome'])\n",
    "\n",
    "# Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "train_TE = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_TE = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "# Train a model\n",
    "train_model(train_TE, valid_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013231,
     "end_time": "2020-10-01T00:25:02.987944",
     "exception": false,
     "start_time": "2020-10-01T00:25:02.974713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The validation score is higher again, from 0.7467 to 0.7491."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014087,
     "end_time": "2020-10-01T00:25:03.015653",
     "exception": false,
     "start_time": "2020-10-01T00:25:03.001566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CatBoost Encoding\n",
    "\n",
    "Finally, we'll look at CatBoost encoding. This is similar to target encoding in that it's based on the target probablity for a given value. However with CatBoost, for each row, the target probability is calculated only from the rows before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:03.056440Z",
     "iopub.status.busy": "2020-10-01T00:25:03.055638Z",
     "iopub.status.idle": "2020-10-01T00:25:07.434323Z",
     "shell.execute_reply": "2020-10-01T00:25:07.435102Z"
    },
    "papermill": {
     "duration": 4.405934,
     "end_time": "2020-10-01T00:25:07.435283",
     "exception": false,
     "start_time": "2020-10-01T00:25:03.029349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC score: 0.7492\n"
     ]
    }
   ],
   "source": [
    "# Create the encoder\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "target_enc.fit(train[cat_features], train['outcome'])\n",
    "\n",
    "# Transform the features, rename columns with _cb suffix, and join to dataframe\n",
    "train_CBE = train.join(target_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_CBE = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "# Train a model\n",
    "train_model(train_CBE, valid_CBE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014069,
     "end_time": "2020-10-01T00:25:07.466991",
     "exception": false,
     "start_time": "2020-10-01T00:25:07.452922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This does slightly better than target encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01397,
     "end_time": "2020-10-01T00:25:07.495595",
     "exception": false,
     "start_time": "2020-10-01T00:25:07.481625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your Turn\n",
    "**[Try encoding categorical features](https://www.kaggle.com/kernels/fork/5407502)** yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 26.887004,
   "end_time": "2020-10-01T00:25:07.647744",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-01T00:24:40.760740",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
