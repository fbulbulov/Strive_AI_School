{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.K. Rowling\n"
     ]
    }
   ],
   "source": [
    "def get_hundred_book_links():\n",
    "    page = requests.get(url=\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1\")\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links_section = soup.find_all('a', class_=\"bookTitle\", href=True)\n",
    "    final_links = [\"https://www.goodreads.com\" + link['href'] for link in links_section]\n",
    "    return final_links\n",
    "\n",
    "\n",
    "get_hundred_book_links()\n",
    "\n",
    "\n",
    "### Individual page\n",
    "def get_author(page_url):\n",
    "    request = requests.get(page_url)\n",
    "    page_soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    author_section = page_soup.find('a', class_=\"authorName\").get_text()\n",
    "    return author_section\n",
    "\n",
    "test = get_author(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test)\n",
    "def main(page_url):\n",
    "    author = get_author()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45345\n"
     ]
    }
   ],
   "source": [
    "def get_num_reviews(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_num_unclean=page_soup.find('meta',itemprop=\"reviewCount\")\n",
    "    get_num_reviews=int(get_num_unclean['content'])\n",
    "    return get_num_reviews\n",
    "test2=get_num_reviews(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average rate\n",
    "def get_avg(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    \n",
    "    get_avg=float(page_soup.find('span',itemprop=\"ratingValue\").get_text())\n",
    "    return get_avg\n",
    "\n",
    "test3=get_avg(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fcb6bad21d7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mget_place\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a[href*=\"/places\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-fcb6bad21d7e>\u001b[0m in \u001b[0;36mget_place\u001b[1;34m(page_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpage_soup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mget_place\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a[href*=\"/places\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# Place (setting)\n",
    "def get_place(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_place=page_soup.select('a[href*=\"/places\"]').get_text()\n",
    "    return get_place\n",
    "test5=get_place(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hogwarts School of Witchcraft and Wizardry, London, England\n"
     ]
    }
   ],
   "source": [
    "def get_place(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_place=page_soup.select('a[href*=\"/places\"]')\n",
    "    place=[]\n",
    "    for x in get_place:\n",
    "        place.append(x.get_text())\n",
    "    return (\", \".join(place))\n",
    "      \n",
    "      \n",
    "test5=get_place(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bram Stoker Award for Works for Young Readers (2003), Anthony Award for Young Adult (2004), Mythopoeic Fantasy Award for Children's Literature (2008), Audie Award for Audiobook of the Year (2004), Books I Loved Best Yearly (BILBY) Awards for Older Readers (2004), Colorado Blue Spruce Young Adult Book Award (2006), Golden Archer Award for Middle/Junior High (2005), Deutscher Jugendliteraturpreis Nominee for Preis der Jugendjury (2004), Carnegie Medal Nominee (2003)\n"
     ]
    }
   ],
   "source": [
    "def get_awards(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards = \", \".join(main_awards)\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def get_awards_list(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards =len((\", \".join(main_awards)).split(','))\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def get_awards_count(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards =len((\", \".join(main_awards)).split(','))\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards_count(\"https://www.goodreads.com/book/show/7260188-mockingjay\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundred_link_grabber(all_books_url):\n",
    "    page = requests.get(url=all_books_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links_section = soup.find_all('a', class_=\"bookTitle\", href=True)\n",
    "    final_links = [\"https://www.goodreads.com\" + link['href'] for link in links_section]\n",
    "    len_links = len(final_links)\n",
    "    print(f\"Succesfully generated {len_links}\")\n",
    "    return final_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(list_of_urls):\n",
    "    pd_data =[]\n",
    "    for book_url in list_of_urls:\n",
    "        print(f\"Working on url: {book_url}\")\n",
    "        request = requests.get(book_url)\n",
    "        page_soup = BeautifulSoup(request.content,'html.parser')\n",
    "        list_of_awards = get_awards_list(page_soup)\n",
    "        number_of_awards = get_awards_count(page_soup)\n",
    "        a_book = {\n",
    "            \"url\": [book_url],\n",
    "            \"list_of_awards\":[list_of_awards],\n",
    "            \"number_of_awards\" :[number_of_awards]}\n",
    "        pd_data.append(a_book)\n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_app(quantity):\n",
    "    \"\"\"\n",
    "    quantity is sets of 100 books\n",
    "    \"\"\"\n",
    "    all_urls =[]\n",
    "    if quantity < 55:\n",
    "        for i in range(quantity):\n",
    "            try:\n",
    "                print(f\"Attempting to take 100 links. Iteration: {i} - awaiting success confirmation\")\n",
    "                list_url = f\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page={i}\"\n",
    "                get_url_data = hundred_link_grabber(list_url)\n",
    "                all_urls.append(get_url_data)\n",
    "            except:\n",
    "                print(f\"***FAILED*** to take links on iteration {i}\")\n",
    "\n",
    "    else:\n",
    "        return \"Selected too many books\"\n",
    "    total_urls = len(all_urls)\n",
    "    print(f\"Finished geneating pagigination urls. total count is {total_urls} urls\")\n",
    "    get_book_data = get_all_books(all_urls)\n",
    "    return get_book_data\n",
    "\n",
    "# Debugger function\n",
    "def debugger_help(book_url):\n",
    "    request = requests.get(book_url)\n",
    "    page_soup = BeautifulSoup(request.content,'html.parser')\n",
    "    return page_soup\n",
    "\n",
    "# Used for merging all the book dictionaries into one for easy dataframe creation\n",
    "def merge_data_dicts(list_of_dictionaries):\n",
    "    all_data = {}\n",
    "    for dict in list_of_dictionaries:\n",
    "        for key, value in dict.items():\n",
    "            if key in all_data.keys():\n",
    "                current_data = all_data[key]\n",
    "                combined_data = current_data + value\n",
    "                all_data[key] = combined_data\n",
    "            else:\n",
    "                all_data[key] = value\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to take 100 links. Iteration: 0 - awaiting success confirmation\n",
      "Succesfully generated 100\n",
      "Attempting to take 100 links. Iteration: 1 - awaiting success confirmation\n",
      "Succesfully generated 100\n",
      "Finished geneating pagigination urls. total count is 2 urls\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_all_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-57b16f7c4ad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_data_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-115-9b9d9b1eaa93>\u001b[0m in \u001b[0;36mmain_app\u001b[1;34m(quantity)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtotal_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Finished geneating pagigination urls. total count is {total_urls} urls\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mget_book_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_books\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_book_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_all_books' is not defined"
     ]
    }
   ],
   "source": [
    "books = main_app(2)\n",
    "df = pd.DataFrame(merge_data_dicts(books))\n",
    "\n",
    "df.to_csv('test.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_app(quantity):\n",
    "    \"\"\"\n",
    "    quantity is sets of 100 books\n",
    "    \"\"\"\n",
    "    all_urls =[]\n",
    "    if quantity < 55:\n",
    "        for i in range(quantity):\n",
    "            try:\n",
    "                print(f\"Attempting to take 100 links. Iteration: {i} - awaiting success confirmation\")\n",
    "                list_url = f\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page={i}\"\n",
    "                get_url_data = hundred_link_grabber(list_url)\n",
    "                all_urls.append(get_url_data)\n",
    "            except:\n",
    "                print(f\"***FAILED*** to take links on iteration {i}\")\n",
    "\n",
    "    else:\n",
    "        return \"Selected too many books\"\n",
    "    total_urls = len(all_urls)\n",
    "    print(f\"Finished generating pagigination urls. total count is {total_urls} urls\")\n",
    "    get_book_data = get_all_books(all_urls)\n",
    "    return get_book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to take 100 links. Iteration: 0 - awaiting success confirmation\n",
      "Succesfully generated 100\n",
      "Finished generating pagigination urls. total count is 1 urls\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_all_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-d70defdbbf72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mbooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_data_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-b92b22d178b0>\u001b[0m in \u001b[0;36mmain_app\u001b[1;34m(quantity)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtotal_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Finished generating pagigination urls. total count is {total_urls} urls\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mget_book_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_books\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_book_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_all_books' is not defined"
     ]
    }
   ],
   "source": [
    "def merge_data_dicts(list_of_dictionaries):\n",
    "    all_data = {}\n",
    "    for dict in list_of_dictionaries:\n",
    "        for key, value in dict.items():\n",
    "            if key in all_data.keys():\n",
    "                current_data = all_data[key]\n",
    "                combined_data = current_data + value\n",
    "                all_data[key] = combined_data\n",
    "            else:\n",
    "                all_data[key] = value\n",
    "    return all_data\n",
    "\n",
    "\n",
    "books = main_app(1)\n",
    "df = pd.DataFrame(merge_data_dicts(books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-5e3696550a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df = pd.DataFrame(merge_data_dicts(books))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scraped_awards.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#df = pd.DataFrame(merge_data_dicts(books))\n",
    "\n",
    "df.to_csv('scraped_awards.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data_dicts(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
